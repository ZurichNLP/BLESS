{
    "use_slurm": true,
    "ntasks": 1,
    "cpus_per_task": 1,
    "n_gpus": 2,
    "gpu_type": "T4",
    "mem": "60GB",
    "time": "01:00:00",
    "model_name_or_path": "models/LLAMA/llama-13b",
    "max_new_tokens": 100,
    "max_memory": 1.0,
    "batch_size": 8
}