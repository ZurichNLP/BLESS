{
    "use_slurm": false,
    "ntasks": 1,
    "cpus_per_task": 1,
    "n_gpus": 7,
    "gpu_type": "A100",
    "mem": "120GB",
    "time": "01:00:00",
    "model_name_or_path": "models/LLAMA/llama-65b",
    "max_new_tokens": 100,
    "max_memory": 1.0,
    "batch_size": 4
}